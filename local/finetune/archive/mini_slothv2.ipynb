{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Model initialization\n",
    "max_seq_length = 10000\n",
    "dtype = None  # None for auto detection\n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Phi-3.5-mini-instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 8,\n",
    "    lora_dropout = 0.1,\n",
    "    bias = \"all\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    use_rslora = True,\n",
    "    loftq_config = None,\n",
    ")\n",
    "\n",
    "# Configure tokenizer with Phi-3 chat template\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"phi-3\",\n",
    "    mapping = {\n",
    "        \"role\": \"role\",\n",
    "        \"content\": \"content\",\n",
    "        \"user\": \"user\",\n",
    "        \"assistant\": \"assistant\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Data preparation function\n",
    "def formatting_prompts_func(examples):\n",
    "    messages_list = examples[\"messages\"]\n",
    "    texts = [tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False) \n",
    "            for messages in messages_list]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Load and process datasets\n",
    "train_file = \"data/input/training_data.jsonl\"\n",
    "eval_file = \"data/input/validation_data.jsonl\"\n",
    "train_dataset = load_dataset('json', data_files=train_file, split='train')\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "eval_dataset = load_dataset('json', data_files=eval_file, split='train')\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
    "\n",
    "# Format the datasets\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "eval_dataset = eval_dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Training configuration\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 16,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,\n",
    "        learning_rate = 1e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        eval_steps = 20,\n",
    "        evaluation_strategy = \"steps\",\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        max_grad_norm = 0.3, \n",
    "        output_dir = \"model\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Enable inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Example inference\n",
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"\"\"\n",
    "\n",
    "Review the following legal document. \n",
    "\n",
    "After reviewing the document, describe what it tells us about what happened during each incident. \n",
    "Focus on who did what, where, and when. \n",
    "Include specific details about locations, dates, times, events, and names of individuals, related to each incident.\n",
    "\n",
    "Below is the document you will review:  \n",
    "H\\nTermination recommended; Resigned\\nTerminated prior to IA findings for failure.\\nACTION\\nOfficer Ornelas resigned on 12/27/2016\\ncollateral duty position.\\nAppeal in process.\\nTermination recommended; Resigned\\nOn 3/10/15, demotion to police officer;\\nprobation.\\nMosqueda resigned on 1/31/19 prior to\\nsuspension from hostage negotiator SWAT\\nNotice to Terminate served. Resigned\\n160-hour suspension, PDSA served\\nTerminated 3/18/15 for failure to pass\\nremoval from training officer position;\\nNotice to Terminate served 7/19/18;\\nResigned 10/14/16 prior to the findings.\\n9/15/14\\n2/24/16:\\n5/1/16.\\n10/10/2016.\\nto pass probation.\\nTermination recommended; Officer\\nprior to the completion of this case.\\n\\u20b2\\nMar 20 2015\\nMar 20 2015\\nFinding Dt\\nApr 04.2018\\nFeb 5 2019\\nSep 10 2014\\nDec 02.2015\\nOct 05 2016\\nF\\nFinding\\nSustained\\nSustained\\nSustained\\nSustained\\nSustained Jun 15 2016\\nSustained\\nSustained |Oct 20 2016\\nSustained.\\nSustained |Jan 25 2017\\nSustained Feb:02-2015\\nSustained\\nFalsification of Work-Related\\nAllegation\\nDishonesty\\nDishonesty; False Statements\\nDocuments; False Statements\\nDishonesty; Falsification of Work-\\nOn-Duty Sexual Relations\\nDocuments\\nRelated Documents\\nDestruction of Evidence\\nFalse Statements\\nFalsification of Work-Related\\\"\\nDishonesty\\n|On-Duty Sexual Relations\\nD\\nOfficer Marc Aguilar [1145]\\nOfficer Kevin Schindler [1260]\\nOfficer Hillary Bjorneboe [1226]\\nOfficer Travis Brewer [1132]\\nOfficer Jeremy Salcido [1273]\\nOfficer Doug Mansker [843]\\nDetective Damacio Diaz [854]\\nOfficer Manuel Ornelas [989]\\nDetective Justin Lewis [1015]\\nOfficer Enrique Mosqueda (1242) |Sexual Solicitation\\nSr. Officer Kyle Ursery [969):\\nC\\nOct 06 2017\\nOct 16 2014\\nOct 16 2014\\nFeb 25 2015\\nJun 06 2016\\nAug 02 2016\\nJan 09 2015\\nOct 13 2018\\nMay 31 2016\\nOct 05 2016\\nInc Received Dt Involved Officer\\nJun 24 2014\\nB\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nType\\nInternal\\nA\\nIA2015-006\n",
    " \"\"\"}\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    test_messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs, \n",
    "    max_new_tokens = 4096,\n",
    "    use_cache = True\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"50k_10k_model\")\n",
    "tokenizer.save_pretrained(\"50k_10k_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "# Initialize device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load base model\n",
    "base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Phi-3.5-mini-instruct\",\n",
    "    max_seq_length=10000,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "# Enable inference mode for base model\n",
    "FastLanguageModel.for_inference(base_model)\n",
    "\n",
    "# Configure base tokenizer\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "base_tokenizer = get_chat_template(\n",
    "    base_tokenizer,\n",
    "    chat_template=\"phi-3\",\n",
    "    mapping={\n",
    "        \"role\": \"role\",\n",
    "        \"content\": \"content\",\n",
    "        \"user\": \"user\",\n",
    "        \"assistant\": \"assistant\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load fine-tuned model - simplified based on documentation\n",
    "ft_model, ft_tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"50k_10k_model\",  # Path to your saved model\n",
    "    max_seq_length=10000,\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "# Enable inference mode for fine-tuned model\n",
    "FastLanguageModel.for_inference(ft_model)\n",
    "\n",
    "# Configure fine-tuned tokenizer\n",
    "ft_tokenizer = get_chat_template(\n",
    "    ft_tokenizer,\n",
    "    chat_template=\"phi-3\",\n",
    "    mapping={\n",
    "        \"role\": \"role\",\n",
    "        \"content\": \"content\",\n",
    "        \"user\": \"user\",\n",
    "        \"assistant\": \"assistant\"\n",
    "    }\n",
    ")\n",
    "\n",
    "def generate_summary(model, tokenizer, text, max_length=4096):\n",
    "    \"\"\"Generate summary using specified model and tokenizer.\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": f\"\"\"Review the following document from a case about a police use of force or misconduct incident. \n",
    "After reviewing the document, describe what it tells us about what happened during each incident. \n",
    "Focus on who did what, where, and when. \n",
    "Include specific details about locations, dates, times, events, and names of individuals, related to each incident.\n",
    "\n",
    "Below is the document you will review:  {text}\"\"\"}]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs,\n",
    "        max_new_tokens=max_length,\n",
    "        use_cache=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    return tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "# Example text to summarize\n",
    "\n",
    "# Example inference\n",
    "input = \"\"\"\n",
    "H\\nTermination recommended; Resigned\\nTerminated prior to IA findings for failure.\\nACTION\\nOfficer Ornelas resigned on 12/27/2016\\ncollateral duty position.\\nAppeal in process.\\nTermination recommended; Resigned\\nOn 3/10/15, demotion to police officer;\\nprobation.\\nMosqueda resigned on 1/31/19 prior to\\nsuspension from hostage negotiator SWAT\\nNotice to Terminate served. Resigned\\n160-hour suspension, PDSA served\\nTerminated 3/18/15 for failure to pass\\nremoval from training officer position;\\nNotice to Terminate served 7/19/18;\\nResigned 10/14/16 prior to the findings.\\n9/15/14\\n2/24/16:\\n5/1/16.\\n10/10/2016.\\nto pass probation.\\nTermination recommended; Officer\\nprior to the completion of this case.\\n\\u20b2\\nMar 20 2015\\nMar 20 2015\\nFinding Dt\\nApr 04.2018\\nFeb 5 2019\\nSep 10 2014\\nDec 02.2015\\nOct 05 2016\\nF\\nFinding\\nSustained\\nSustained\\nSustained\\nSustained\\nSustained Jun 15 2016\\nSustained\\nSustained |Oct 20 2016\\nSustained.\\nSustained |Jan 25 2017\\nSustained Feb:02-2015\\nSustained\\nFalsification of Work-Related\\nAllegation\\nDishonesty\\nDishonesty; False Statements\\nDocuments; False Statements\\nDishonesty; Falsification of Work-\\nOn-Duty Sexual Relations\\nDocuments\\nRelated Documents\\nDestruction of Evidence\\nFalse Statements\\nFalsification of Work-Related\\\"\\nDishonesty\\n|On-Duty Sexual Relations\\nD\\nOfficer Marc Aguilar [1145]\\nOfficer Kevin Schindler [1260]\\nOfficer Hillary Bjorneboe [1226]\\nOfficer Travis Brewer [1132]\\nOfficer Jeremy Salcido [1273]\\nOfficer Doug Mansker [843]\\nDetective Damacio Diaz [854]\\nOfficer Manuel Ornelas [989]\\nDetective Justin Lewis [1015]\\nOfficer Enrique Mosqueda (1242) |Sexual Solicitation\\nSr. Officer Kyle Ursery [969):\\nC\\nOct 06 2017\\nOct 16 2014\\nOct 16 2014\\nFeb 25 2015\\nJun 06 2016\\nAug 02 2016\\nJan 09 2015\\nOct 13 2018\\nMay 31 2016\\nOct 05 2016\\nInc Received Dt Involved Officer\\nJun 24 2014\\nB\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nType\\nInternal\\nA\\nIA2015-006\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Generate summaries from both models\n",
    "print(\"Base Model Summary:\")\n",
    "base_summary = generate_summary(base_model, base_tokenizer, input)\n",
    "print(base_summary)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Fine-tuned Model Summary:\")\n",
    "ft_summary = generate_summary(ft_model, ft_tokenizer, input)\n",
    "print(ft_summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
