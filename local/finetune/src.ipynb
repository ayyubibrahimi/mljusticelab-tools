{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "max_seq_length = 10000\n",
    "dtype = None  \n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Phi-3.5-mini-instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    modules_to_save = [\"lm_head\"],\n",
    "    lora_alpha = 8,\n",
    "    lora_dropout = 0.1,\n",
    "    bias = \"all\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    use_rslora = True,\n",
    "    loftq_config = None,\n",
    ")\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Configure tokenizer with Phi-3 chat template\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"phi-3\",\n",
    "    mapping = {\n",
    "        \"role\": \"role\",\n",
    "        \"content\": \"content\",\n",
    "        \"user\": \"user\",\n",
    "        \"assistant\": \"assistant\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Data preparation function\n",
    "def formatting_prompts_func(examples):\n",
    "    messages_list = examples[\"messages\"]\n",
    "    texts = [tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False) \n",
    "            for messages in messages_list]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# Load and process datasets\n",
    "train_file = \"data/input/training_data.jsonl\"\n",
    "eval_file = \"data/input/validation_data.jsonl\"\n",
    "train_dataset = load_dataset('json', data_files=train_file, split='train')\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "eval_dataset = load_dataset('json', data_files=eval_file, split='train')\n",
    "print(f\"Eval dataset size: {len(eval_dataset)}\")\n",
    "\n",
    "\n",
    "# train_dataset = train_dataset.select(range(200))\n",
    "# eval_dataset = eval_dataset.select(range(20))\n",
    "\n",
    "# Format the datasets\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "eval_dataset = eval_dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Training configuration\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = eval_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        per_device_eval_batch_size = 2,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_steps = 50,\n",
    "        max_steps = 250,\n",
    "        learning_rate = 1e-5,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        eval_steps = 25,\n",
    "        evaluation_strategy = \"steps\",\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.1,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        max_grad_norm = .3,\n",
    "        output_dir = \"model\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "# Enable inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Example inference\n",
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"\"\"\n",
    "\n",
    "Read the following document.\n",
    "After reading the document, describe what it tells us.  \n",
    "Focus on who did what, where, and when. \n",
    "Include specific details about locations, dates, times, events, and names of individuals. \n",
    "\n",
    "H\\nTermination recommended; Resigned\\nTerminated prior to IA findings for failure.\\nACTION\\nOfficer Ornelas resigned on 12/27/2016\\ncollateral duty position.\\nAppeal in process.\\nTermination recommended; Resigned\\nOn 3/10/15, demotion to police officer;\\nprobation.\\nMosqueda resigned on 1/31/19 prior to\\nsuspension from hostage negotiator SWAT\\nNotice to Terminate served. Resigned\\n160-hour suspension, PDSA served\\nTerminated 3/18/15 for failure to pass\\nremoval from training officer position;\\nNotice to Terminate served 7/19/18;\\nResigned 10/14/16 prior to the findings.\\n9/15/14\\n2/24/16:\\n5/1/16.\\n10/10/2016.\\nto pass probation.\\nTermination recommended; Officer\\nprior to the completion of this case.\\n\\u20b2\\nMar 20 2015\\nMar 20 2015\\nFinding Dt\\nApr 04.2018\\nFeb 5 2019\\nSep 10 2014\\nDec 02.2015\\nOct 05 2016\\nF\\nFinding\\nSustained\\nSustained\\nSustained\\nSustained\\nSustained Jun 15 2016\\nSustained\\nSustained |Oct 20 2016\\nSustained.\\nSustained |Jan 25 2017\\nSustained Feb:02-2015\\nSustained\\nFalsification of Work-Related\\nAllegation\\nDishonesty\\nDishonesty; False Statements\\nDocuments; False Statements\\nDishonesty; Falsification of Work-\\nOn-Duty Sexual Relations\\nDocuments\\nRelated Documents\\nDestruction of Evidence\\nFalse Statements\\nFalsification of Work-Related\\\"\\nDishonesty\\n|On-Duty Sexual Relations\\nD\\nOfficer Marc Aguilar [1145]\\nOfficer Kevin Schindler [1260]\\nOfficer Hillary Bjorneboe [1226]\\nOfficer Travis Brewer [1132]\\nOfficer Jeremy Salcido [1273]\\nOfficer Doug Mansker [843]\\nDetective Damacio Diaz [854]\\nOfficer Manuel Ornelas [989]\\nDetective Justin Lewis [1015]\\nOfficer Enrique Mosqueda (1242) |Sexual Solicitation\\nSr. Officer Kyle Ursery [969):\\nC\\nOct 06 2017\\nOct 16 2014\\nOct 16 2014\\nFeb 25 2015\\nJun 06 2016\\nAug 02 2016\\nJan 09 2015\\nOct 13 2018\\nMay 31 2016\\nOct 05 2016\\nInc Received Dt Involved Officer\\nJun 24 2014\\nB\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nInternal\\nType\\nInternal\\nA\\nIA2015-006\n",
    " \"\"\"}\n",
    "]\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    test_messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids = inputs, \n",
    "    max_new_tokens = 4096,\n",
    "    use_cache = True\n",
    ")\n",
    "\n",
    "print(tokenizer.batch_decode(outputs)[0])\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save_pretrained(\"testy_model\")\n",
    "tokenizer.save_pretrained(\"testy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel\n",
    "# import torch\n",
    "\n",
    "# # Initialize device\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Load base model\n",
    "# base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name=\"unsloth/Phi-3.5-mini-instruct\",\n",
    "#     max_seq_length=10000,\n",
    "#     load_in_4bit=True\n",
    "# )\n",
    "\n",
    "# # Enable inference mode for base model\n",
    "# FastLanguageModel.for_inference(base_model)\n",
    "\n",
    "# # Configure base tokenizer\n",
    "# from unsloth.chat_templates import get_chat_template\n",
    "# base_tokenizer = get_chat_template(\n",
    "#     base_tokenizer,\n",
    "#     chat_template=\"phi-3\",\n",
    "#     mapping={\n",
    "#         \"role\": \"role\",\n",
    "#         \"content\": \"content\",\n",
    "#         \"user\": \"user\",\n",
    "#         \"assistant\": \"assistant\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# # Load fine-tuned model - simplified based on documentation\n",
    "# ft_model, ft_tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name=\"2k_10k_model\",  # Path to your saved model\n",
    "#     max_seq_length=10000,\n",
    "#     load_in_4bit=True\n",
    "# )\n",
    "\n",
    "# # Enable inference mode for fine-tuned model\n",
    "# FastLanguageModel.for_inference(ft_model)\n",
    "\n",
    "# # Configure fine-tuned tokenizer\n",
    "# ft_tokenizer = get_chat_template(\n",
    "#     ft_tokenizer,\n",
    "#     chat_template=\"phi-3\",\n",
    "#     mapping={\n",
    "#         \"role\": \"role\",\n",
    "#         \"content\": \"content\",\n",
    "#         \"user\": \"user\",\n",
    "#         \"assistant\": \"assistant\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# def generate_summary(model, tokenizer, text, max_length=4096):\n",
    "#     \"\"\"Generate summary using specified model and tokenizer.\"\"\"\n",
    "#     messages = [{\"role\": \"user\", \"content\": f\"\"\"\n",
    "# Summarize each event.\n",
    "\n",
    "# Below is the document you will review:  {text}\"\"\"}]\n",
    "    \n",
    "#     inputs = tokenizer.apply_chat_template(\n",
    "#         messages,\n",
    "#         tokenize=True,\n",
    "#         add_generation_prompt=True,\n",
    "#         return_tensors=\"pt\"\n",
    "#     ).to(device)\n",
    "    \n",
    "#     outputs = model.generate(\n",
    "#         input_ids=inputs,\n",
    "#         max_new_tokens=max_length,\n",
    "#         use_cache=True,\n",
    "#         temperature=0.7,\n",
    "#         top_p=0.95,\n",
    "#         top_k=10,\n",
    "#         do_sample=True,        \n",
    "#     )\n",
    "    \n",
    "#     return tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "# # Example text to summarize\n",
    "\n",
    "# # Example inference\n",
    "# input = \"\"\"\n",
    "\n",
    "# | IA No | Type | Inc Received Dt | Involved Officer | Allegation | Finding | Finding Dt | ACTION |\n",
    "# |-------|------|----------------|------------------|------------|---------|------------|---------|\n",
    "# | IA2014-014 | Internal | Jun 24 2014 | Officer Marc Aguilar [1145] | Dishonesty; False Statements | Sustained | Sep 10 2014 | Termination recommended; Resigned 9/15/14 |\n",
    "# | IA2014-022 | Internal | Oct 16 2014 | Officer Hillary Bjorneboe [1226] | Falsification of Work-Related Documents | Sustained | Mar 20 2015 | Terminated 3/18/15 for failure to pass probation. |\n",
    "# | IA2014-022 | Internal | Oct 16 2014 | Officer Travis Brewer [1132] | Dishonesty; Falsification of Work-Related Documents | Sustained | Mar 20 2015 | Termination recommended; Resigned 5/1/16. |\n",
    "# | IA2015-002 | Internal | Jan 09 2015 | Sr. Officer Kyle Ursery [969] | On-Duty Sexual Relations | Sustained | Feb 02 2015 | On 3/10/15, demotion to police officer; removal from training officer position; suspension from hostage negotiator SWAT collateral duty position. |\n",
    "# | IA2015-006 | Internal | Feb 25 2015 | Detective Damacio Diaz [854] | Falsification of Work-Related Documents; False Statements | Sustained | Dec 02 2015 | Notice to Terminate served. Resigned 2/24/16. |\n",
    "# | IA2016-008 | Internal | May 31 2016 | Officer Doug Mansker [843] | Destruction of Evidence | Sustained | Oct 05 2016 | 160-hour suspension, PDSA served 10/10/2016. |\n",
    "# | IA2016-011 | Internal | Jun 06 2016 | Officer Jeremy Salcido [1273] | Dishonesty | Sustained | Jun 15 2016 | Terminated prior to IA findings for failure to pass probation. |\n",
    "# | IA2016-016 | Internal | Aug 02 2016 | Detective Justin Lewis [1015] | False Statements | Sustained | Oct 20 2016 | Resigned 10/14/16 prior to the findings. |\n",
    "# | IA2016-022 | Internal | Oct 05 2016 | Officer Manuel Ornelas [989] | On-Duty Sexual Relations | Sustained | Jan 25 2017 | Officer Ornelas resigned on 12/27/2016 prior to the completion of this case. |\n",
    "# | IA2017-011 | Internal | Oct 06 2017 | Officer Kevin Schindler [1260] | Dishonesty | Sustained | Apr 04 2018 | Notice to Terminate served 7/19/18; Appeal in process. |\n",
    "# | IA2018-017 | Internal | Oct 13 2018 | Officer Enrique Mosqueda [1242] | Sexual Solicitation | Sustained | Feb 5 2019 | Termination recommended; Officer Mosqueda resigned on 1/31/19 prior to |\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# # Generate summaries from both models\n",
    "# print(\"Base Model Summary:\")\n",
    "# base_summary = generate_summary(base_model, base_tokenizer, input)\n",
    "# print(base_summary)\n",
    "# print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "# print(\"Fine-tuned Model Summary:\")\n",
    "# ft_summary = generate_summary(ft_model, ft_tokenizer, input)\n",
    "# print(ft_summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
